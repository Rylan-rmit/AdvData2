{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Assignment 2: Milestone I Natural Language Processing\n",
    "## Task 2&3\n",
    "#### Student Name: XXXX XXXX\n",
    "#### Student ID: 000000\n",
    "\n",
    "Date: XXXX\n",
    "\n",
    "Version: 1.0\n",
    "\n",
    "Environment: Python 3 and Jupyter notebook\n",
    "\n",
    "Libraries used: please include all the libraries you used in your assignment, e.g.,:\n",
    "* pandas\n",
    "* re\n",
    "* numpy\n",
    "\n",
    "## Introduction\n",
    "You should give a brief information of this assessment task here.\n",
    "\n",
    "<span style=\"color: red\"> Note that this is a sample notebook only. You will need to fill in the proper markdown and code blocks. You might also want to make necessary changes to the structure to meet your own needs. Note also that any generic comments written in this notebook are to be removed and replace with your own words.</span>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Importing libraries "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Code to import libraries as you need in this assessment, e.g.,\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 2. Generating Feature Representations for Job Advertisement Descriptions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "...... Sections and code blocks on buidling different document feature represetations\n",
    "\n",
    "\n",
    "<span style=\"color: red\"> You might have complex notebook structure in this section, please feel free to create your own notebook structure. </span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'gensim'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_16204\\1960061137.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mcollections\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mCounter\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0msklearn\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfeature_extraction\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtext\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mTfidfVectorizer\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 4\u001b[1;33m \u001b[1;32mfrom\u001b[0m \u001b[0mgensim\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmodels\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mFastText\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mKeyedVectors\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      5\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      6\u001b[0m \u001b[1;32mdef\u001b[0m \u001b[0mload_vocabulary\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'gensim'"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from collections import Counter\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from gensim.models import FastText, KeyedVectors\n",
    "\n",
    "def load_vocabulary():\n",
    "    with open(\"vocab.txt\", \"r\") as f:\n",
    "        vocab_dict = {line.strip().split(\":\")[0]: int(line.strip().split(\":\")[1]) for line in f.readlines()}\n",
    "    return vocab_dict\n",
    "\n",
    "def generate_count_vector(tokens, vocab_dict):\n",
    "    word_counts = Counter(tokens)\n",
    "    return {vocab_dict[word]: count for word, count in word_counts.items() if word in vocab_dict}\n",
    "\n",
    "def save_count_vectors_to_file(df):\n",
    "    with open(\"count_vectors.txt\", \"w\") as f:\n",
    "        for index, row in df.iterrows():\n",
    "            vector_str = \",\".join([f\"{idx}:{freq}\" for idx, freq in row['Count Vectors'].items()])\n",
    "            f.write(f\"#{row['Webindex']}, {vector_str}\\n\")\n",
    "\n",
    "def generate_unweighted_embedding(tokens, model):\n",
    "    vectors = [model[word] for word in tokens if word in model.vocab]\n",
    "    return sum(vectors) / len(vectors) if vectors else []\n",
    "\n",
    "def generate_weighted_embedding(tokens, idx, tfidf_vectors, model, vocab_dict):\n",
    "    vectors = []\n",
    "    for word in set(tokens):\n",
    "        if word in model.vocab:\n",
    "            weight = tfidf_vectors[idx, vocab_dict[word]]\n",
    "            vectors.append(weight * model[word])\n",
    "    return sum(vectors) / len(vectors) if vectors else []\n",
    "\n",
    "# Load data\n",
    "df = pd.read_csv(\"processed_job_ads.csv\")\n",
    "\n",
    "# Load vocabulary\n",
    "vocab_dict = load_vocabulary()\n",
    "\n",
    "# Generate and save count vectors\n",
    "df['Count Vectors'] = df['Tokenized Description'].apply(lambda tokens: generate_count_vector(tokens, vocab_dict))\n",
    "save_count_vectors_to_file(df)\n",
    "\n",
    "# Load FastText model\n",
    "model = KeyedVectors.load_word2vec_format('path_to_FastText_embeddings.bin', binary=True)\n",
    "df['Unweighted Embeddings'] = df['Tokenized Description'].apply(lambda tokens: generate_unweighted_embedding(tokens, model))\n",
    "\n",
    "# Generate TF-IDF Weighted embeddings\n",
    "tfidf_vectorizer = TfidfVectorizer(vocabulary=vocab_dict, use_idf=True, norm=None)\n",
    "tfidf_vectors = tfidf_vectorizer.fit_transform(df['Tokenized Description'].apply(' '.join))\n",
    "df['Weighted Embeddings'] = [generate_weighted_embedding(row['Tokenized Description'], idx, tfidf_vectors, model, vocab_dict) for idx, row in df.iterrows()]\n",
    "\n",
    "# Here, you can save 'Unweighted Embeddings' and 'Weighted Embeddings' as needed.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Saving outputs\n",
    "Save the count vector representation as per spectification.\n",
    "- count_vectors.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# code to save output data..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 3. Job Advertisement Classification"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "...... Sections and code blocks on buidling classification models based on different document feature represetations. \n",
    "Detailed comparsions and evaluations on different models to answer each question as per specification. \n",
    "\n",
    "<span style=\"color: red\"> You might have complex notebook structure in this section, please feel free to create your own notebook structure. </span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Code to perform the task...\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summary\n",
    "Give a short summary and anything you would like to talk about the assessment tasks here."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Couple of notes for all code blocks in this notebook\n",
    "- please provide proper comment on your code\n",
    "- Please re-start and run all cells to make sure codes are runable and include your output in the submission.   \n",
    "<span style=\"color: red\"> This markdown block can be removed once the task is completed. </span>"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
